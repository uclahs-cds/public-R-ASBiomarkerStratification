---
title: 'Active Surveillance Progression Prediction'
author: 'Stefan Eng'
output:
  bookdown::pdf_document2:
    template: ../boutros_template.tex
    keep_tex: true
  html_notebook: default
bibliography:  bibliography.bib
csl: nature-no-superscript.csl
nocite: |
  @BPG
---

```{r setup, include=FALSE}
library(BoutrosLab.ASBiomarkerSynergy);
library(BoutrosLab.plotting.general);
library(kableExtra);
library(gridExtra);
library(magrittr);
library(here);
library(caret);
library(pROC);
library(rpart.plot);

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, fig.align = 'center', out.width = '60%', fig.pos = 'H');

axis.cex <- .7
lab.cex <- .8
strip.cex <- 0.45

km.arguments <- list(
  xaxis.cex = axis.cex,
  yaxis.cex = axis.cex,
  main.cex = 1.4,
  xlab.cex = lab.cex,
  ylab.label = 'Estimated survival probability',
  ylab.cex = lab.cex,
  risktable.fontsize = 14,
  key.groups.cex = 1,
  key.stats.cex = 1,
  key.stats.y.pos = 0.5
  );

as.data <- default.load.data();
biodb <- as.data$biodb;

valid.patients <- biodb$NoUpgradeAndProgressed == 0 | is.na(biodb$NoUpgradeAndProgressed);

biodb.valid <- biodb[valid.patients, ];
```

# Introduction

## Study design and objectives
  Dr. Michael Liss, a surgeon at University of Texas Health Sciences Center San Antonio (UTHSCSA), put together a cohort of active surveillance (AS) patients.
Many biomarkers were measured via blood, urine, biopsies, radiology and genetic tests.
The key clinical problem is unrecognized aggressive disease, which both hinders those patients directly and more broadly reduces confidence in AS.
Some patients voluntarily seek treatment (approximately 15%) without a need which is expensive, has long-term morbidities, and quality-of-life impacts.
We aim to best identify which patients should exit AS and progress to treatment.
This also will give confidence for the patients who remain on AS that their decision is justified.
From there we aim find the best sequence of tests and biomarkers to investigate in a prospective clinical trial.
  
## Data description
In this cohort there are $N = `r nrow(biodb)`$ patients.
There are three variables that are of interest to predict.
The first, `BiopsyUpgraded`, is whether the patient's research study biopsy increased cancer grade from the most recent biopsy results.
The second, `ProgressedToTreatment`, is whether the patient progressed to treatment.
Finally we have `Prostatectomy` which indicates whether the patient had a prostatectomy.
The Prostate Health Index (PHI) and PHI density have been used in detection of prostate cancer [@Druskin2017].
The biomarkers used are shown in Table \@ref(tab:biomarker-categories).
Along with these biomarkers, we computed the PSA Density as `PSAHyb / ProstateVolume` and the PHI Density as `PHI / ProstateVolume`. 
The severity of the prostate cancers were measured on the Gleason scale/ISUP grade group [@ISUP2016] and described in Table \@ref(tab:gleason-isup).
A full description of all of the variables available is found in Table \@ref(tab:variable-key).

```{r gleason-isup}
gleason.isup.table <- data.frame(
  gleason = paste('Gleason Score', c('$\\leq 6$', '3 + 4 = 7', '4 + 3 = 7', '8', '9-10')),
  grade.group = paste('Grade Group', 1:5)
)

gleason.isup.table %>%
  kable(
    escape = FALSE,
    col.names = c('Gleason Score', 'ISUP Grade Group'),
    caption = 'ISUP grade group definitions from Gleason scores') %>%
  kable_styling()
```

```{r biomarker-categories}
kable(as.data$bio.categories[,1:2], caption = 'Biomarkers categories') %>%
  kable_styling() %>%
  collapse_rows(columns = 1)
```

```{r prediction-vars}
pred.vars.xtabs <- xtabs(~ BiopsyUpgraded + ProgressedToTreatment + Prostatectomy, data = biodb, addNA = TRUE)
pred.vars.df <- as.data.frame(ftable(pred.vars.xtabs))

pred.table <- reshape(pred.vars.df, idvar = c('BiopsyUpgraded', 'ProgressedToTreatment'), timevar = 'Prostatectomy', direction = 'wide')

row.order <- with(pred.table, order(BiopsyUpgraded, ProgressedToTreatment))
prostatectomy.cols <- paste0(c('no', 'yes'), ' (N=', table(biodb$Prostatectomy), ')')
overall.col <- paste0('Overall (N=', nrow(biodb), ')')

pred.table$Overall <- rowSums(pred.table[, c(3,4)])

pred.table[row.order, ] %>%
  kable(row.names = FALSE,
    booktabs = TRUE,
    align =  c('c', 'c', 'c', 'c'),
    col.names = c('Biopsy Upgraded', 'Progressed To Treatment', prostatectomy.cols, overall.col),
    caption = 'Comparison of prediction variables of interest') %>%
  kable_styling() %>%
  collapse_rows(columns = 1) %>%
  add_header_above(c(' ' = 2, 'Prostatectomy' = 2, ' ' = 1), align = 'c')
```

The variable `PreviousISUP` is the most recent prostate cancer ISUP grade group (GG) rating prior to research biopsy.
The ISUP grade group is computed again in the variable `StudyHighestISUP` after the research MRI.
We compare the progression of the cancers by the ISUP grade groups from the previous result to the highest study result in Table \@ref(tab:previous-highest-isup).
```{r previous-highest-isup}
progressed <- rep(NA, length(biodb$PreviousISUP))
progressed[biodb$PreviousISUP < biodb$StudyHighestISUP] <- 'Increased';
progressed[biodb$PreviousISUP > biodb$StudyHighestISUP] <- 'Decreased';
progressed[biodb$PreviousISUP == biodb$StudyHighestISUP] <- 'No Change';

kable(t(table(progressed)), caption = 'Comparison of pre-research biopsy ISUP grade group to post research MRI ISUP GG');

isup.names <- c('No Cancer', 1:5, 'NA');

isup.table <- with(biodb, table(PreviousISUP, StudyHighestISUP, useNA='ifany'));
isup.table <- cbind(rownames(isup.table), isup.table)

isup.table %>%
  kable(
    row.names = FALSE,
    booktabs = TRUE,
    align =  'c',
    col.names = c('Previous ISUP GG', isup.names),
    caption = 'Compare the progression of the cancers by the ISUP grade groups from the previous result to the highest study result'
    ) %>%
  kable_styling() %>%
  add_header_above(c(' ' = 1, 'Study Highest ISUP Grade Group' = length(levels(biodb$StudyHighestGleason)) + 1), align = 'c')
```

```{r surgery-isup-compare}
surgery.isup.xtabs <- xtabs(~ ProgressedToTreatment + Prostatectomy + StudyHighestISUP, data = biodb, addNA = TRUE)
surgery.isup.df <- as.data.frame(ftable(surgery.isup.xtabs))

surgery.isup.wide <- reshape(surgery.isup.df, idvar = c('ProgressedToTreatment', 'Prostatectomy'), timevar = 'StudyHighestISUP', direction = 'wide')

row.order <- order(surgery.isup.wide$ProgressedToTreatment, surgery.isup.wide$Prostatectomy)# [-2] Add this is we want to remove useless row

surgery.isup.wide[row.order, ] %>%
    kable(row.names = FALSE,
    booktabs = TRUE,
    col.names = c('Progressed To Treatment', 'Prostatectomy', isup.names),
    caption = 'Comparing highest ISUP grade group for those progressed to treatment') %>%
  kable_styling() %>%
  collapse_rows(columns = 1) %>%
  add_header_above(c(' ' = 2, 'Study Highest ISUP Grade Group' = length(isup.names)), align = 'c')
```

# Results

## Descriptive Statistics

```{r demographics-bx, results= 'hide', out.width='90%', fig.cap='Demographics by race and whether biopsy was upgraded.'}
demographic.vars <- c('Age', 'Weight', 'Height', 'BMI');
bx.plots <- lapply(demographic.vars, demographics.boxplot, biodb = biodb, x = 'BiopsyUpgraded', cond = 'Race', yaxis.cex = axis.cex, xaxis.cex = axis.cex, ylab.cex = lab.cex, xlab.cex = lab.cex, strip.cex = strip.cex);
do.call(gridExtra::grid.arrange, bx.plots);
```

```{r demographics-prog, results= 'hide', out.width='90%', fig.cap='Demographics by race and whether patient progressed to treatment.'}
demographic.vars <- c('Age', 'Weight', 'Height', 'BMI');
prog.plots <- lapply(demographic.vars, demographics.boxplot, biodb = biodb, x = 'ProgressedToTreatment', cond = 'Race', yaxis.cex = axis.cex, xaxis.cex = axis.cex, ylab.cex = lab.cex, xlab.cex = lab.cex, strip.cex = strip.cex);
do.call(gridExtra::grid.arrange, prog.plots);
```

```{r bx-biomarker-summary}
tab.form <- '~ p2PSA +  freePSA + PSAHyb + PSADensity + SOCPSA + PHI + PHIDensity + ProstateVolume + TNFaAverage'
t1.bx <- table1::table1(as.formula(paste(tab.form, 'BiopsyUpgraded', sep='|')), data = biodb);
table1.to.kable(t1.bx, caption = 'Biomarker summaries for biopsy upgraded.') %>%
  add_header_above(c(' ' = 1, 'Biopsy Upgraded' = 2, ' ' = 1))
```

```{r prog-biomarker-summary}
# TODO: Update render.default to always include missing?
t1 <- table1::table1(as.formula(paste(tab.form, 'ProgressedToTreatment', sep='|')), data = biodb);
table1.to.kable(t1, caption = 'Biomarker summaries for progressed to treatment.') %>%
  add_header_above(c(' ' = 1, 'Progressed To Treatment' = 2, ' ' = 1))
```

```{r, out.width = '100%', fig.cap='Correlation heapmap with test with test methodology labels.'}
create.heatmap.AS(biodb);
```

### Time-to-event data
```{r}
stopifnot(
    all(!is.na(biodb$DaysDxToLastClinicalAppt))
    );
stopifnot(
    all(!is.na(biodb$DaysDxToLastReview))
    );
stopifnot(
    all(is.na(biodb$BiopsyResult) == is.na(biodb$DaysBxToLastReview))
    );
stopifnot(
    all(is.na(biodb$BiopsyResult) == is.na(biodb$DaysBxToLastClinicalAppt))
    );
```
All patients have values for the days from diagnosis to the last clinical appointment `DaysDxToLastClinicalAppt` and last review `DaysDxToLastReview`.
The patients that had a biopsy have values for variables `DaysBxToLastClinicalAppt` and `DaysBxToLastReview`.
If a patient progressed to treatment, then the days from diagnosis are in `DaysDxToProgression`.
If they had a biopsy and progressed to treatment then `DaysDxToProgression` will contain the days between the biopsy and progression.
We show the days to progression from biopsy in Figure \@ref(fig:days-bx-progression), the days to progression from diagnosis in Figure \@ref(fig:days-dx-progression), and the days to biopsy upgrade in \@ref(fig:days-dx-upgrade).

```{r days-bx-progression, fig.cap='Days to progression from biopsy for entire cohort.'}
# Create a Surv object from survival package
progression.surv.bx <- do.call(
    what = survival::Surv,
    args = surv.format(biodb$DaysBxToProgression, biodb$DaysBxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = progression.surv.bx,
      main = 'Overall Days-to-Progression from Biopsy',    
      xlab.label = 'Time to progression from biopsy (Days)'
      )
    )
  )
```

```{r days-dx-progression, fig.cap='Days to progression from diagnosis for entire cohort.'}
progression.surv.dx <- do.call(
    what = survival::Surv,
    args = surv.format(biodb$DaysDxToProgression, biodb$DaysDxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = progression.surv.dx,
      main = 'Overall Days-to-Progression from Diagnosis',
      xlab.label = 'Time to progression from diagnosis (Days)'
      )
    )
  )
```

```{r days-dx-upgrade, fig.cap='Days to biopsy upgrade from diagnosis'}
# Create a Surv object from survival package
upgrade.surv <- do.call(
    what = survival::Surv,
    args = surv.format(biodb$DaysDxToUpgrade, biodb$DaysDxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = upgrade.surv,
      main = 'Overall Days-to-Upgrade from Diagnosis',
      xlab.label = 'Time to upgrade since diagnosis (Days)'
      )
    )
  )
```

## Predictive Analysis
```{r}
# seed <- 1313;
# With TNFaSTD
# seed <- 42;
# Without TNFaSTD
seed <- 2626;
model.names <- c('rpart', 'gbm', 'xgb');
targets <- c(
    'BiopsyUpgraded',
    'Prostatectomy',
    'ProgressedToTreatment');
metric <- 'PR-AUC';

models <- lapply(targets, function(tg) {
    model.file.names <- here(paste0('models/', model.names, '_', tg, '_', metric, '_', seed, '_model.RDS'));
    res <- lapply(model.file.names, readRDS);
    names(res) <- model.names;
    res
});
names(models) <- targets;
```

We predict the three variables: `ProgressedToTreatment`, `BiopsyUpgraded`, `Prostatectomy`.
We remove all of the patients that did not had their biopsy upgraded (`BiopsyUpgraded = 0`) and still progressed to treatment (`ProgressedToTreatment = 1`).
This indicates that progression to treatment was voluntary.
From the Table \@ref(tab:prediction-vars), we see that then any indication of an aggressive disease is first indicated by biopsy upgraded.
In this sense it is the most fundamental to predict as if a patient is predicted not to have their biopsy upgraded then they will not be predicted to have progressed to treatment or have a prostatectomy.

For each of these variable we compare the results from three models: a regression tree (`rpart`), gradient boosting machine (`gbm`), and eXtreme Gradient Boosting (`xgboost`).
The regression tree model is the most interpretable as it produces a single decision tree.
The other models produce better accuracy as well as $F_1$ scores but require more work to interpret.

The variables in \@ref(tab:variable-set) were used as the initial set of variables for `ProgressedToTreatment` and `Prostatectomy`. In the case of `BiopsyUpgraded`, the variable `BiopsyResult` was removed from the predictor variables.
```{r variable-set}
var.names <- models$ProgressedToTreatment$gbm$finalModel$var.names;
mid <- ceiling(length(var.names) / 2);
# Add '' if variable lengths are not even
var2 <- rep('', mid);
var2[1:(mid - 1)] <- var.names[(mid + 1):length(var.names)];
var.names.df <- data.frame(
  var1 = var.names[1:mid],
  var2 = var2
)

kable(
  var.names.df,
  col.names = NULL,
  booktabs = T,
  caption = 'Variables used to predict ProgressedToTreatment and Prostatectomy') %>%
  kable_styling(position =  'center') %>%
  add_header_above(c('Variables' = 2), align = 'c')
```

### ROC and PR Curves
For each of the targets, `ProgressedToTreatment`, `BiopsyUpgraded`, and `Prostatectomy` we construct Receiver operating characteristic (ROC) and Precision-Recall curves.
The sensitivity/recall, specificity, and precision are all computed from the cross-validation folds to give an estimate of out of sample performance.
```{r roc-curves, out.width='90%', fig.cap='Cross-Validation ROC Curves for Progressed to Treatment and Biopsy Upgraded'}
cex.main <- 1.2
cex.title <- 1.4

models.roc <- lapply(models, function(mods) {
  lapply(mods, function(m) {
      bestPreds <- with(m, merge(pred, bestTune));
      pROC::roc(predictor = bestPreds$yes, response = bestPreds$obs, direction = '<', levels = c('no', 'yes'));
  })
})
```

```{r prog-roc, out.width='90%', fig.cap='Cross-Validation ROC and Precision-Recall Curves for Progressed to Treatment. The optimal (Youden's J statistic) is indicated with a point on the ROC curve.'}
roc.pr.plot(models.roc$ProgressedToTreatment, cex.main = cex.main)
mtext('Progressed to Treatment Cross-Validation Curves', side = 3, line = -2, outer = TRUE, cex = cex.title);
```

```{r bx-roc, out.width='90%', fig.cap='Cross-Validation ROC and Precision-Recall Curves for Biopsy Upgraded. The optimal (Youden's J statistic) is indicated with a point on the ROC curve.'}
roc.pr.plot(models.roc$BiopsyUpgraded, cex.main = cex.main)
mtext('Biopsy Upgraded Cross-Validation Curves', side = 3, line = -2, outer = TRUE, cex = cex.title);
```

```{r prostate-roc, out.width='90%', fig.cap='Cross-Validation ROC and Precision-Recall Curves for Prostatectomy. The optimal (Youden's J statistic) is indicated with a point on the ROC curve.'}
roc.pr.plot(models.roc$Prostatectomy, cex.main = cex.main)
mtext('Prostatectomy Cross-Validation Curves', side = 3, line = -2, outer = TRUE, cex = cex.title);
```

### Optimal Operating Point
```{r optimal-op-point, cache=TRUE}
# cost.matrix <- lapply(1:3, function(x) matrix(c(0,x,1,0), byrow = TRUE, nrow = 2))
# cost.matrix <- matrix(c(0,3,1,0), byrow = TRUE, nrow = 2)
cost.matrix <- matrix(c(0,2,1,0), byrow = TRUE, nrow = 2)
thresholds <- seq(.01, .99, length.out = 50)

statistics <- c('prob_threshold', 'Sensitivity', 'Specificity', 'Pos Pred Value', 'Neg Pred Value', 
'Precision', 'Recall', 'F1', 'Prevalence', 'Detection Rate',
'Detection Prevalence', 'Balanced Accuracy', 'Accuracy', 'Kappa'
)

optimal.thresholds <- lapply(models, function(mods) {
  lapply(mods, function(m) {
      optimal.threshold.train(m, thresholds = thresholds, cost.matrix = cost.matrix)
  })
})

# Use the ROC levels instead
optimal.thresholds.youden <- lapply(models.roc, function(rocs) {
  lapply(rocs, function(r) {
      as.numeric(coords(r, 'best')[1])
  })
})

thresholds.info.list <- lapply(names(optimal.thresholds), function(x) {
  target.list <- models[[x]]

  res <- lapply(names(target.list), function(y) {
    m <- target.list[[y]]
    threshold <- optimal.thresholds[[x]][[y]]
    threshold.roc <- optimal.thresholds.youden[[x]][[y]]

    thres.res <- colMeans(threshold.summary.stats(m, threshold), na.rm = TRUE);
    thres.res$model <- m$method;
    thres.res$method <- 'cost';
    thres.res$target <- x;
    thres.res$threshold <- threshold;

    thres.res.roc <- colMeans(threshold.summary.stats(m, threshold.roc), na.rm = TRUE);
    thres.res.roc$model <- m$method;
    thres.res.roc$method <- 'roc';
    thres.res.roc$target <- x;
    thres.res.roc$threshold <- threshold.roc;

    rbind(thres.res, thres.res.roc)
  })

  do.call(rbind.data.frame, res)
})

names(thresholds.info.list) <- names(optimal.thresholds);

thresholds.info <- do.call(rbind.data.frame, thresholds.info.list)
```

Each of the models outputs a probability being in class 1, e.g. the probability of biopsy upgraded, or progression to treatment.
By default the models threshold anything above 0.5 as class 1 and anything below as 0.
We want to find a better threshold value, called the operating point.

The first method we test for finding the optimal operating point is to maximize Youden's J statistic [@Youden1950] which is defined as
$$
J = \text{sensitivity} + \text{specificity} - 1
$$
The second method we use to find the optimal operating point is to make a false negative FN (when we predict indolent disease when it truly is aggressive) 2 times as costly as a false positive FP.
For each threshold the cost is computed for each of the folds in the 10-fold cross-validation and averaged across all 10 folds and 5 repetitions.
Then the optimal operating point is selected as the threshold with the minimum cost.

We show how to find the optimal point for predicting whether a patient progressed to treatment.
```{r, fig.cap='Optimal operating point for the Progressed to Treatment prediction models.', cache=TRUE}
threshold.cost.gbm <- cost.threshold.train(models$ProgressedToTreatment$gbm, thresholds = thresholds, cost.matrix = cost.matrix)

threshold.cost.rpart <- cost.threshold.train(models$ProgressedToTreatment$rpart, thresholds = thresholds, cost.matrix = cost.matrix)

threshold.cost.xgb <- cost.threshold.train(models$ProgressedToTreatment$xgb, thresholds = thresholds, cost.matrix = cost.matrix)

n.models <- length(models$ProgressedToTreatment);

threshold.plot.df <- rbind(
  data.frame(threshold = thresholds, cost = threshold.cost.gbm, model = 'gbm'),
  data.frame(threshold = thresholds, cost = threshold.cost.rpart, model = 'rpart'),
  data.frame(threshold = thresholds, cost = threshold.cost.xgb, model = 'xgb'))

min.thresholds <- thresholds[c(which.min(threshold.cost.gbm), which.min(threshold.cost.rpart), which.min(threshold.cost.xgb))]
xat <- c(0, sort(min.thresholds), 0.5, 1)

BoutrosLab.plotting.general::create.scatterplot(
  formula = cost ~ threshold,
  groups = threshold.plot.df$model,
  data = threshold.plot.df,
  col = default.colours(n.models),
  xat = xat,
  xaxis.lab = round(xat, 2),
  xaxis.cex = 1,
  yaxis.cex = 1,
  ylab.cex = 1.2,
  xlab.cex = 1.2,
  ylab.label = 'mean cost',
  main = 'Progressed to Treatment\nOptimal operating points',
  main.cex = 1.3,
  type = 'l',
  lwd = 2,
  abline.v = min.thresholds,
  abline.col = default.colours(n.models),
  key = list(
    text = list(
      lab = names(models$ProgressedToTreatment),
      cex = 1,
      col = 'black'
    ),
    lines = list(
      type = 'l',
      col = default.colours(n.models),
      cex = 1,
      lwd = 2
    ),
    x = 0.8,
    y = 0.2
  )
)
```

The results are very similar for the $J$ statistic optimization and the cost-weighted method.
The only model in which the results differ dramatically are in the prostatectomy prediction.
In the cost-weighted method the threshold is optimized at 0 or 1 which results in all positive or all negative predictions.
Using the $J$ statistic prevents the models from predicting the same class. 
We show summary statistics in Table \@ref(tab:threshold-results) for the optimal thresholds for both J statistic and cost-weighted methods.
```{r threshold-results, fig.cap='Summary statistics for the optimal operating points for each model'}
cols <- c('target', 'model', 'method', 'threshold', 'Accuracy', 'Sensitivity', 'Specificity', 'Precision'
  #'Pos Pred Value', 'Neg Pred Value',
  ,'F1'
  )

thresholds.table <- thresholds.info[, cols]
# Break camel case into newlines
thresholds.table$target <- kableExtra::linebreak(camel.to.spaces(thresholds.table$target, replace = '\n'), align = 'c')
num.cols <- 4:length(cols)
thresholds.table[, num.cols] <- lapply(thresholds.table[, num.cols], function(x) round(as.numeric(x), 2))

kable(
  thresholds.table,
  digits = 2,
  row.names = FALSE,
  caption = 'Summary statistics for the different operating points, targets and models. Bold is the optimal model with cut-point selected from J statistic.',
  escape = F) %>%
  kable_styling() %>%
  column_spec(1, width_min = '7em') %>%
  collapse_rows(columns = 1:3) %>%
  row_spec(c(4, 10, 16), bold = TRUE)
```

## Cut-points for time-to-event analysis
The gradient boosted model (gbm) provided the best predictive power of the models.
We use the predictions from this model to show that days until the patient progressed or had the biopsy upgraded for each of the prediction groups.

```{r cutpoint-days-prog-bx, fig.cap = 'Days to progression from biopsy for the prediction groups'}
prog.gbm.preds <- ifelse(predict(models$ProgressedToTreatment$gbm, type = 'prob')[, 'yes'] > optimal.thresholds$ProgressedToTreatment$gbm, 1, 0)

progression.surv.bx.valid <- do.call(
    what = survival::Surv,
    args = surv.format(biodb.valid$DaysBxToProgression, biodb.valid$DaysBxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      # Is this right to remove the missing values?
      survival.object = progression.surv.bx.valid[!is.na(progression.surv.bx.valid)],
      patient.groups = prog.gbm.preds[!is.na(progression.surv.bx.valid)],
      main = 'Overall Days-to-Progression from Biopsy',
      xlab.label = 'Time to upgrade since biopsy (Days)'
      )
    )
  )
```

```{r cutpoint-days-prog-dx, fig.cap = 'Days to progression from diagnosis for the prediction groups'}
progression.surv.dx.valid <- do.call(
    what = survival::Surv,
    args = surv.format(biodb.valid$DaysDxToProgression, biodb.valid$DaysDxToLastReview)
    );


do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = progression.surv.dx.valid,
      patient.groups = prog.gbm.preds,
      main = 'Days-to-Progression from diagnosis',
      xlab.label = 'Time to progression from diagnosis (Days)'
      )
    )
  )
```

```{r cutpoint-days-upgrade-dx, fig.cap='Days to biopsy upgrade from diagnosis for the prediction groups.'}
bx.gbm.preds <- rep(NA, nrow(biodb.valid))
bx.gbm.preds[!is.na(biodb.valid$BiopsyUpgraded)] <- ifelse(predict(models$BiopsyUpgraded$gbm, type = 'prob')[, 'yes'] > optimal.thresholds$BiopsyUpgraded$gbm, 1, 0)

upgrade.surv.valid <- do.call(
    what = survival::Surv,
    args = surv.format(biodb.valid$DaysDxToUpgrade, biodb.valid$DaysDxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = upgrade.surv.valid,
      patient.groups = bx.gbm.preds,
      main = 'Overall Days-to-Upgrade from Diagnosis',
      xlab.label = 'Time to upgrade since diagnosis (Days)'
      )
    )
  )
```


## Variable Importance for Progressed to Treatment
The regression tree output is simple to interpret but does not provide the best predictions.
The GBM is not as easy to interpret but has a measure of variable importance of the predictors.
We compare the models' variable importance ranks to see important variables across the models.

```{r}
var.imp.joined <- compare.var.imp(models$ProgressedToTreatment, include.ranks = TRUE)[, -1]
                   
var.imp.joined <- var.imp.joined[order(var.imp.joined$mean.rank),]
kable(
  x = head(var.imp.joined[, c('mean.rank', 'gbm.rank', 'xgb.rank', 'rpart.rank')], n = 25),
  caption = paste('Top 25 variable importance rankings out of', nrow(var.imp.joined), 'variables'), digits = 2,
  col.names = c('Mean rank', 'GBM rank', 'XGB rank', 'rpart rank')
  )
```

## Decision Trees
The GBM models perform much better than the rpart models.
We include the rpart decision tree models as they are easy to interpret.

```{r decision-tree-bx, fig.cap='Decision tree for Biopsy Upgraded prediction.'}
rpart.plot(models$BiopsyUpgraded$rpart$finalModel);
```

```{r decision-tree-prog, fig.cap='Decision tree for Progressed to Treatment prediction.'}
rpart.plot(models$ProgressedToTreatment$rpart$finalModel);
```

```{r decision-tree-prostate, out.width='70%', fig.cap='Decision tree for Prostatectomy prediction.'}
rpart.plot(models$Prostatectomy$rpart$finalModel);
```

# Next steps

Following the results from this work we can begin to investigate, with input from Dr. Michael Liss, if there are ways to simplify or cheapen the testing done.
Further work could be done on optimal model building if additional cost parameters are given for each test.
This could progress into a combination of accuracy and cost benefit models.

# Conclusion/Discussion

From the results we found that gradient boosted tree methods work quite well on this dataset even in the presence of class imbalance.
The decision tree methods became too simple to provide good predictive accuracy for each of the targets.
Many of the classic predictors (PHI, RSI signals) used to predict aggressive prostate cancer were found to be important in our model as well.

# Methods

## Software
```{r reproducibility, echo = FALSE, results='asis'}
## Reproducibility info
# options(width = 120)
# utils::sessionInfo() sessioninfo::session_info()

utils::toLatex(utils::sessionInfo())
```

\newpage

# References

<div id='refs'></div>

\newpage

# (APPENDIX) Appendix {-}

# Codebook

```{r variable-key}
as.data$biokey[, c('Column.ID', 'Definition')] %>%
kable(
  escape = FALSE,
  booktabs = TRUE,
  longtable = TRUE,
  caption = 'Original variables from dataset.',
  col.names = c('Variable', 'Definition')
  ) %>%
  kable_styling(font_size = 9,
                latex_options = c('repeat_header'),
                repeat_header_continued = '\\textit{(Continued on Next Page...)}') %>%
  column_spec(2, width = '11cm')
```

# Model Fitting
All of the models were validated using 10-fold cross-validation repeated 5 times.
That is, we partition the data set into 10 parts and use 9 parts to train the model and the last to evaluate the model.
Several metrics are computed based on the results such as $F_1$ score, area under the ROC curve (ROC-AUC), area under the precision-recall curve, accuracy, sensitivity, and specificity.
This process is repeated so that each part of the partition is used to validate exactly once.
We repeat this entire process 5 times so that 10 random partitions are generated.
This results in a distribution for the metrics which is an approximation for how to models will perform out of sample.
For each of the models we performed a grid-search to find the optimal parameters.
We list the optimal parameters for the GBM model in Table \@ref(tab:gbm-grid).
The area under the precision-recall curve was used as the (threshold invariant) metric for which the parameters were tuned.

```{r gbm-grid}
gbm.params <- models$BiopsyUpgraded$gbm$modelInfo$parameters
rownames(gbm.params) <- gbm.params$parameter

gbm.grid <- list(interaction.depth = expr(c(1, 5, 9)),
                            n.trees = expr(seq(50, 1500, by = 50)),
                            shrinkage = expr(c(0.001, 0.01, 0.1)),
                            n.minobsinnode = expr(10)
                            )

gbm.params$range <- gbm.grid[rownames(gbm.params)]
gbm.params$length <- lapply(gbm.grid[rownames(gbm.params)], function(x) length(eval(x)))
gbm.params$best.bx <- round(t(models$BiopsyUpgraded$gbm$bestTune[rownames(gbm.params)]))
gbm.params$best.prog <- round(t(models$ProgressedToTreatment$gbm$bestTune[rownames(gbm.params)]))
gbm.params$best.surg <- round(t(models$Prostatectomy$gbm$bestTune[rownames(gbm.params)]))

gbm.caption <- paste0('Hyperparameters for GBM model. The total grid size is: ', Reduce('*', gbm.params$length));
gbm.params[, c('label', 'range', 'length', 'best.bx', 'best.prog', 'best.surg')] %>%
  kable(
    booktabs = TRUE,
    caption = gbm.caption,
    col.names = c('label', 'range', 'length', 'BX Best', 'TRT Best', 'Surgery Best')) %>%
  kable_styling(full_width = TRUE) %>%
  column_spec(1, width = '2.3cm')
```

```{r xgb-grid, eval = F}                            
xgb.grid <- list(
    nrounds = expr(seq(200, 1000, by = 50)),
    eta = expr(c(0.025, 0.05, 0.1, 0.3)),
    max_depth = expr(c(4, 5, 6)),
    gamma = expr(0),
    colsample_bytree = expr(1),
    min_child_weight = expr(1),
    subsample = expr(1)
    );

xgb.params <- models$BiopsyUpgraded$xgb$modelInfo$parameters
rownames(xgb.params) <- xgb.params$parameter

xgb.params$range <- xgb.grid[rownames(xgb.params)]
xgb.params$length <- lapply(xgb.grid[rownames(xgb.params)], function(x) length(eval(x)))
xgb.params$best <- t(models$BiopsyUpgraded$xgb$bestTune[rownames(xgb.params)])

xgb.caption <- paste0('Hyperparameters for XGB model for biopsy upgraded prediction. The total grid size is: ', Reduce('*', xgb.params$length));
xgb.params[, c('label', 'range', 'length', 'best')] %>%
  kable(booktabs = TRUE, caption = xgb.caption) %>%
  kable_styling(full_width = TRUE) %>%
  column_spec(1, width = '2.3cm')
```


