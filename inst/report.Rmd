---
title: 'Active Surveillance Progression Prediction'
author: 'Stefan Eng'
output:
  bookdown::pdf_document2:
    number_sections: false
  html_notebook: default
---

```{r setup, include=FALSE}
library(ProstateCancer.ASBiomarkerSynergy);
library(BoutrosLab.plotting.general);
library(kableExtra);
library(gridExtra);
library(magrittr);
library(here);
library(caret);
# library(MLeval);
library(pROC)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, fig.align = 'center', out.width = '50%')

axis.cex <- .7
lab.cex <- .8
strip.cex <- 0.45

km.arguments <- list(
  xaxis.cex = axis.cex,
  yaxis.cex = axis.cex,
  main.cex = 1.4,
  xlab.cex = lab.cex,
  ylab.label = 'Estimated survival probability',
  ylab.cex = lab.cex,
  risktable.fontsize = 14,
  key.groups.cex = 1,
  key.stats.cex = 1,
  key.stats.y.pos = 0.5
  );

biodb <- default.load.data(onlyBiodb = TRUE);
```

## Data
In this cohort there are $N = `r nrow(biodb)`$ patients.
There are three variables that are of interest to predict.
The first, `BiopsyUpgraded`, is whether the patient's research study biopsy increased cancer grade from the most recent biopsy results.
The second, `ProgressedToTreatment`, is whether the patient progressed to treatment.
Finally we have `Prostatectomy` which indicates whether the patient had a prostatectomy.

```{r}
pred.vars.xtabs <- xtabs(~ BiopsyUpgraded + ProgressedToTreatment + Prostatectomy, data = biodb, addNA = TRUE)
pred.vars.df <- as.data.frame(ftable(pred.vars.xtabs))

pred.table <- reshape(pred.vars.df, idvar = c('BiopsyUpgraded', 'ProgressedToTreatment'), timevar = 'Prostatectomy', direction = 'wide')

row.order <- with(pred.table, order(BiopsyUpgraded, ProgressedToTreatment))
prostatectomy.cols <- paste0(0:1, ' (N=', table(biodb$Prostatectomy), ')')
overall.col <- paste0('Overall (N=', nrow(biodb), ')')

pred.table$Overall <- rowSums(pred.table[row.order, c(3,4)])

pred.table[row.order, ] %>%
  kable(row.names = FALSE,
    booktabs = TRUE,
    align =  c('c', 'c', 'c', 'c'),
    col.names = c('Biopsy Upgraded', 'Progressed To Treatment', prostatectomy.cols, overall.col),
    caption = 'Comparison of prediction variables of interest') %>%
  kable_styling() %>%
  collapse_rows(columns = 1) %>%
  add_header_above(c(' ' = 2, 'Prostatectomy' = 2, ' ' = 1), align = 'c')
```

The severity of the prostate cancers were measured on the Gleason scale.
The variable `PreviousGleason` is the most recent prostate cancer Gleason score rating prior to research biopsy.
The Gleason score is computed again in the variable `StudyHighestGleason` after the research MRI.
We compare the progression of the cancers by the Gleason grades.
```{r}
progressed <- rep(NA, length(biodb$PreviousGleason))
progressed[biodb$PreviousGleason < biodb$StudyHighestGleason] <- 'Increased';
progressed[biodb$PreviousGleason > biodb$StudyHighestGleason] <- 'Decreased';
progressed[biodb$PreviousGleason == biodb$StudyHighestGleason] <- 'No Change';

kable(t(table(progressed)), caption = 'Comparison of pre-research biopsy Gleason score to post research MRI Gleason score');

with(biodb, {
  table(PreviousGleason, StudyHighestGleason, useNA='ifany') %>%
  kable(booktabs = TRUE,
    align =  'c') %>%
  kable_styling() %>%
  add_header_above(c(' ' = 1, 'Study Highest Gleason' = length(levels(StudyHighestGleason)) + 1), align = 'c')
})
```

### Demographics

#### Biopsy Upgraded
```{r, results= 'hide', out.width='90%'}
demographic.vars <- c('Age', 'Weight', 'Height', 'BMI');
bx.plots <- lapply(demographic.vars, demographics.boxplot, biodb = biodb, x = 'BiopsyUpgraded', cond = 'Race', yaxis.cex = axis.cex, xaxis.cex = axis.cex, ylab.cex = lab.cex, xlab.cex = lab.cex, strip.cex = strip.cex);
do.call(gridExtra::grid.arrange, bx.plots);
```

#### Progressed to Treatment
```{r, results= 'hide', out.width='90%'}
demographic.vars <- c('Age', 'Weight', 'Height', 'BMI');
prog.plots <- lapply(demographic.vars, demographics.boxplot, biodb = biodb, x = 'ProgressedToTreatment', cond = 'Race', yaxis.cex = axis.cex, xaxis.cex = axis.cex, ylab.cex = lab.cex, xlab.cex = lab.cex, strip.cex = strip.cex);
do.call(gridExtra::grid.arrange, prog.plots);
```

### Table Summaries
```{r}
# TODO: Update render.default to always include missing?
t1 <- table1::table1(~ p2PSA +  freePSA + PSAHyb + SOCPSA + PHI | ProgressedToTreatment, data = biodb);
table1.to.kable(t1) %>%
  add_header_above(c(' ' = 1, 'Progressed To Treatment' = 2, ' ' = 1))
```

```{r}
t1.bx <- table1::table1(~ p2PSA +  freePSA + PSAHyb + SOCPSA + PHI | BiopsyUpgraded, data = biodb);
table1.to.kable(t1.bx) %>%
  add_header_above(c(' ' = 1, 'Biopsy Upgraded' = 2, ' ' = 1))
```

### Correlation Heatmap
```{r, out.width = '100%'}
create.heatmap.AS(biodb);
```

### Time-to-event data

```{r}
stopifnot(
    all(!is.na(biodb$DaysDxToLastClinicalAppt))
    );
stopifnot(
    all(!is.na(biodb$DaysDxToLastReview))
    );
stopifnot(
    all(is.na(biodb$BiopsyResult) == is.na(biodb$DaysBxToLastReview))
    );
stopifnot(
    all(is.na(biodb$BiopsyResult) == is.na(biodb$DaysBxToLastClinicalAppt))
    );
```
All patients have values for the days from diagnosis to the last clinical appointment `DaysDxToLastClinicalAppt` and last review `DaysDxToLastReview`.
The patients that had a biopsy have values for variables `DaysBxToLastClinicalAppt` and `DaysBxToLastReview`.
If a patient progressed to treatment, then the days from diagnosis are in `DaysDxToProgression`.
If they had a biopsy and progressed to treatment then `DaysDxToProgression` will contain the days between the biopsy and progression.

#### Overall Days to Progression from Biopsy/Diagnosis
```{r}
# Create a Surv object from survival package
progression.surv.bx <- do.call(
    what = survival::Surv,
    args = surv.format(biodb$DaysBxToProgression, biodb$DaysBxToLastReview)
    );

progression.surv.dx <- do.call(
    what = survival::Surv,
    args = surv.format(biodb$DaysDxToProgression, biodb$DaysDxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = progression.surv.bx,
      main = 'Overall Days-to-Progression from Biopsy',    
      xlab.label = 'Time to progression from biopsy (Days)'
      )
    )
  )

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = progression.surv.dx,
      main = 'Overall Days-to-Progression from Diagnosis',
      xlab.label = 'Time to progression from diagnosis (Days)'
      )
    )
  )
```

#### Overall Time-to-Upgrade from Diagnosis
```{r}
# Create a Surv object from survival package
upgrade.surv <- do.call(
    what = survival::Surv,
    args = surv.format(biodb$DaysDxToUpgrade, biodb$DaysDxToLastReview)
    );

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = upgrade.surv,
      main = 'Overall Days-to-Upgrade from Diagnosis',
      xlab.label = 'Time to upgrade since diagnosis (Days)'
      )
    )
  )
```

## Predictive Analysis
```{r}
seed <- 1313;
model.names <- c('rpart', 'gbm');
targets <- c(
    'BiopsyUpgraded',
    'Prostatectomy',
    'ProgressedToTreatment');
metric <- 'PR-AUC';

models <- lapply(targets, function(tg) {
    model.file.names <- here(paste0('models/', model.names, '_', tg, '_', metric, '_', seed, '_model.RDS'));
    res <- lapply(model.file.names, readRDS);
    names(res) <- model.names;
    res
});
names(models) <- targets;
```

We predict the three variables: `ProgressedToTreatment`, `BiopsyUpgraded`, `Prostatectomy`.
For each of these variable we compare the results from three models: a regression tree (`rpart`), gradient boosting machine (`gbm`), and eXtreme Gradient Boosting (`xgboost`).
The regression tree model is the most interpretable as it produces a single decision tree.
The other models produce better accuracy as well as $F_1$ scores but require more work to interpret. The following variables were used as the initial set of variables for `ProgressedToTreatment` and `Prostatectomy`. In the case of `BiopsyUpgraded`, the variable `BiopsyResult` was removed from the predictor variables.

### Method
For each of the models we performed a grid-search to find the optimal parameters.
The area under the ROC curve was used as the (threshold invariant) metric for which the parameters were tuned.

```{r}
kable(models$ProgressedToTreatment$gbm$finalModel$var.names, col.names = 'Variable', booktabs = T) %>%
  kable_styling(position =  'center')
```

### ROC and PR Curve
```{r}
# https://stackoverflow.com/a/37261201/1351718
roc.prog.gbm <- pROC::roc(predictor = models$ProgressedToTreatment$gbm$pred$yes, response = models$ProgressedToTreatment$gbm$pred$obs)
roc.prog.rpart <- pROC::roc(predictor = models$ProgressedToTreatment$rpart$pred$yes, response = models$ProgressedToTreatment$rpart$pred$obs)

coords(roc.prog.gbm, 'best')
coords(roc.prog.rpart, 'best')

par(pty="s")
plot(roc.prog.gbm, las = 1, col = "red")
plot(roc.prog.rpart, las = 1, add = TRUE, col = "blue", xlim = c(1, 0))

# Plot PR Curves
# Plot the Precision-Recall curve
plot(precision ~ recall,
  coords(roc.prog.gbm, "all", ret = c("recall", "precision"), transpose = FALSE),
  type="l", las = 1, col = "red")

lines(precision ~ recall,
  coords(roc.prog.rpart, "all", ret = c("recall", "precision"), transpose = FALSE),
  type="l", las = 1, col = "blue")
```

### Operating Point
```{r}
# cost.matrix <- lapply(1:3, function(x) matrix(c(0,x,1,0), byrow = TRUE, nrow = 2))
# cost.matrix <- matrix(c(0,3,1,0), byrow = TRUE, nrow = 2)
cost.matrix <- matrix(c(0,2,1,0), byrow = TRUE, nrow = 2)
thresholds <- seq(0, 1, length.out = 100)

statistics <- c("prob_threshold", "Sensitivity", "Specificity", "Pos Pred Value", "Neg Pred Value", 
"Precision", "Recall", "F1", "Prevalence", "Detection Rate", 
"Detection Prevalence", "Balanced Accuracy", "Accuracy", "Kappa"
)

optimal.thresholds <- lapply(models, function(mods) {
  lapply(mods, function(m) {
      optimal.threshold.train(m, thresholds = thresholds, cost.matrix = cost.matrix)
  })
})

thresholds.info.list <- lapply(names(optimal.thresholds), function(x) {
  target.list <- models[[x]]
  
  res <- lapply(names(target.list), function(y) {
    m <- target.list[[y]]
    threshold <- optimal.thresholds[[x]][[y]]
    thres.res <- colMeans(threshold.summary.stats(m, threshold), na.rm = TRUE)
    thres.res$method <- m$method
    thres.res$threshold <- threshold
    thres.res
  })
  
  res.df <- do.call(rbind.data.frame, res)
  rownames(res.df) <- names(target.list)
  res.df
})

names(thresholds.info.list) <- names(optimal.thresholds);

thresholds.info <- do.call(rbind.data.frame, thresholds.info.list)
```

Each of the models outputs a probability being in class 1, e.g. the probability of biopsy upgraded, or progression to treatment.
By default the models threshold anything above 0.5 as class 1 and anything below as 0.
We want to find a better threshold value, called the operating point.
To find the optimal operating point we make a false negative FN (when we predict indolent disease when it truly is aggresive) 3 times as costly as a false positive FP.
For each threshold the cost is computed for each of the folds in the 10-fold cross-validation and averaged across all 10 folds and 5 repetitions.
Then the optimal operating point is selected as the threshold with the minimum cost.

We show how to find the optimal point for predicting whether a patient progressed to treatment.
```{r, fig.cap="Optimal operating point for the Progressed to Treatment prediction models."}
threshold.cost.gbm <- cost.threshold.train(models$ProgressedToTreatment$gbm, thresholds = thresholds, cost.matrix = cost.matrix)

threshold.cost.rpart <- cost.threshold.train(models$ProgressedToTreatment$rpart, thresholds = thresholds, cost.matrix = cost.matrix)

threshold.plot.df <- rbind(
  data.frame(threshold = thresholds, cost = threshold.cost.gbm, model = "gbm"),
  data.frame(threshold = thresholds, cost = threshold.cost.rpart, model = "rpart"))

min.thresholds <- thresholds[c(which.min(threshold.cost.gbm), which.min(threshold.cost.rpart))]
xat <- c(0, sort(min.thresholds), 0.5, 1)

BoutrosLab.plotting.general::create.scatterplot(
  formula = cost ~ threshold,
  groups = threshold.plot.df$model,
  data = threshold.plot.df,
  col = default.colours(2),
  xat = xat,
  xaxis.lab = round(xat, 2),
  xaxis.cex = 1,
  yaxis.cex = 1,
  ylab.cex = 1.2,
  xlab.cex = 1.2,
  main = "Optimal operating points for Progressed to Treatment prediction",
  main.cex = 1.3,
  type = "l",
  abline.v = min.thresholds,
  abline.col = default.colours(2),
  key = list(
    text = list(
      lab = c('GBM', 'rpart'),
      cex = 1,
      col = 'black'
    ),
    lines = list(
      type = 'l',
      col = default.colours(2),
      cex = 1
    ),
    x = 0.8,
    y = 0.75
  )
)
```

Then we show the results for each of the models at the given optimal operating points for each model
```{r operating-points, fig.cap='Summary statistics for the optimal operating points for each model'}
# cols <- c("prob_threshold", "Sensitivity", "Specificity", "Pos Pred Value", "Neg Pred Value", 
# "Precision", "Recall", "F1", "Prevalence", "Accuracy"
# )
kable(thresholds.info, digits = 3) %>%
  kable_styling()
```


### Prediction Results
All of the models were validated using 10-fold cross-validation repeated 5 times.
That is, we partition the data set into 10 parts and use 9 parts to train the model and the last to evaluate the model.
Several metrics are computed based on the results such as $F_1$ score, area under the ROC curve (ROC-AUC), area under the precision-recall curve, accuracy, sensitivity, and specificity.
This process is repeated so that each part of the partition is used to validate exactly once.
We repeat this entire process 5 times so that 10 random partitions are generated.
This results in a distribution for the metrics which is an approximation for how to models will perform out of sample.

#### Biopsy Upgraded
First we predict whether a patients biopsy will be upgraded.

```{r bx-metrics}
bx.resamps <- resamples(
  models$BiopsyUpgraded);

trellis.par.set(caretTheme())
dotplot(bx.resamps, metric = c('F', 'ROC-AUC', 'PR-AUC', 'Accuracy', 'Sens', 'Spec'), main = 'Biopsy Upgraded Model Comparison')
```

The regression tree produces the worst results in almost all metrics except for specificity.
The final regression tree is shown in Figure \@ref(fig:bx-rpart).
We can see that the final regression the only variable used in the prediction is the RSI Lesion Signal.
```{r bx-rpart, fig.cap='Regresion tree for predicting whether biopsy will be upgraded. Only the RSI Lesion Signal variable is used.'}
rpart.plot::rpart.plot(models$BiopsyUpgraded$rpart$finalModel, main = 'Biopsy Upgraded Regression Tree')
```

#### Progressed To Treatment
Next we predict whether a patient will progress to treatment.
```{r prog-metrics}
prog.resamps <- resamples(models$ProgressedToTreatment);

#evalm(prog.gbm.F.model)
# prog.gbm.F.model$results

dotplot(prog.resamps, metric = c('F', 'ROC-AUC', 'PR-AUC', 'Accuracy', 'Sens', 'Spec'), main = 'Progressed To Treatment Model Comparison')
```

```{r prog-rpart, fig.cap='Regresion tree for predicting whether the patient will progress to treatment.', out.width = '75%'}
rpart.plot::rpart.plot(models$ProgressedToTreatment$rpart$finalModel, main = 'Progressed-to-Treatment Regression Tree')
```

#### Prostatectomy
Finally, we predict whether a patient will require a prostatectomy.
```{r prostate-metrics}
prostate.resamps <- resamples(models$Prostatectomy);

dotplot(prostate.resamps, metric = c('F', 'ROC-AUC', 'PR-AUC', 'Accuracy', 'Sens', 'Spec'), main = 'Prostatectomy Model Comparison')
```

```{r prostate-rpart, fig.cap='Regresion tree for predicting whether the patient will require a prostatectomy.', out.width = '75%'}
rpart.plot::rpart.plot(models$Prostatectomy$rpart$finalModel, main = 'Prostatectomy Regression Tree')
```


## Cut-points for time-to-event analysis
The gradient boosted model (gbm) provided the best predictive power of the models.
We use the predictions from this model to show that days until the patient progressed or had the biopsy upgraded for each of the prediction groups.

### Progressed To Treatment
```{r}
prog.gbm.preds <- ifelse(predict(models$ProgressedToTreatment$gbm, type = 'prob')[, 'yes'] > optimal.thresholds$ProgressedToTreatment$gbm, 1, 0)

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      # Is this right to remove the missing values?
      survival.object = progression.surv.bx[!is.na(progression.surv.bx)],
      patient.groups = prog.gbm.preds[!is.na(progression.surv.bx)],
      main = 'Overall Days-to-Progression from Biopsy',
      xlab.label = 'Time to upgrade since biopsy (Days)'
      )
    )
  )

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = progression.surv.dx,
      patient.groups = prog.gbm.preds,
      main = 'Overall Days-to-Progression from Diagnosis',
      xlab.label = 'Time to progression from diagnosis (Days)'
      )
    )
  )
```

### Days to Upgrade from Diagnosis
```{r}
bx.gbm.preds <- rep(NA, nrow(biodb))
bx.gbm.preds[!is.na(biodb$BiopsyUpgraded)] <- ifelse(predict(models$BiopsyUpgraded$gbm, type = 'prob')[, 'yes'] > optimal.thresholds$BiopsyUpgraded$gbm, 1, 0)
# bx.gbm.preds <- as.factor(bx.gbm.preds)
# levels(bx.gbm.preds) <- c('0', '1')

do.call(
  what = BoutrosLab.plotting.survival::create.km.plot,
  args = c(
    km.arguments,
    list(
      survival.object = upgrade.surv,
      patient.groups = bx.gbm.preds,
      main = 'Overall Days-to-Upgrade from Diagnosis',
      xlab.label = 'Time to upgrade since diagnosis (Days)'
      )
    )
  )
```


## Variable Importance for Progressed to Treatment
The regression tree output is simple to interpret but does not provide the best predictions.
The other models are not as easy to interpret but have measures of variable importance of the predictors.
We compare the three models' variable importance ranks to see important variables across all models.

```{r}
#plot(varImp(prog.gbm.F.model), top = 25, main = 'Variable Importance Progressed-to-Treatment XGB')
#plot(varImp(bx.gbm.F.model), top = 25, main = 'Variable Importance Biopsy Upgraded XGB')
#plot(varImp(prostate.gbm.F.model), top = 25, main = 'Variable Importance Prostatectomy XGB')

#prog.model.list <- list(prog.gbm.F.model, prog.rpart.F.model)
# names(prog.model.list) <- c('gbm', 'xgb', 'rpart')

var.imp.joined <- compare.var.imp(models$ProgressedToTreatment, include.ranks = TRUE)[, -1]
                   
var.imp.joined <- var.imp.joined[order(var.imp.joined$mean.rank),]
kable(
  x = head(var.imp.joined[, c('mean.rank', 'gbm.rank', 'rpart.rank')], n = 25),
  caption = paste('Top 25 variable importance rankings out of', nrow(var.imp.joined), 'variables'), digits = 2,
  col.names = c('Mean rank', 'rpart rank', 'GBM rank')
  )
```
